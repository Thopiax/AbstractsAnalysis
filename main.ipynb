{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Papers based on contents of their abstracts\n",
    "\n",
    "Author: Rafael Ballestiero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize']=[50,30]\n",
    "plt.rcParams['font.size']=22\n",
    "plt.rcParams['font.weight']='bold'\n",
    "plt.rcParams['axes.titlesize'] = 28\n",
    "plt.rcParams['axes.labelsize'] = 24\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Construct preprocessed abstracts with custom filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gensim.parsing import preprocessing\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, \\\n",
    "                                         strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short, stem_text\n",
    "\n",
    "from gensim.utils import has_pattern\n",
    "\n",
    "import pattern.en as en\n",
    "\n",
    "assert has_pattern()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/text_allyears.csv\", header=0, index_col=0).dropna(subset=[\"Abstract\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_references = [\"Tong, C., Nagarajan, M., & Cheng, Y. (2016). Operational impact of service innovations in \",  \"Easton, F. F., & Pullman, M. E. (2001). Optimizing service attributes: The seller\\'s utility problem\", \"Customer efficiency, channel usage, and firm performance in retail banking\"]\n",
    "\n",
    "bad_indexes = []\n",
    "for ref in duplicate_references:\n",
    "    bad_indexes.append(df[df[\"Reference\"].apply(lambda x: ref in x)].index[0])\n",
    "    \n",
    "# df.drop(bad_indexes).reset_index(drop=True).to_csv(\"./data/text_allyears.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_pattern = re.compile(u\"[^\\d]*\\([0-9]{4}\\)\\.?\\s*([^\\.]+\\.?).*\")\n",
    "def parse_title(reference):\n",
    "    match = re.match(title_pattern, reference)\n",
    "    \n",
    "    if match is None:\n",
    "        print(reference)\n",
    "        raise Exception(\"Bad pattern\")\n",
    "        \n",
    "    return match.groups()[0]\n",
    "\n",
    "def reference_preprocessing(df):\n",
    "    return df[\"Reference\"].apply(parse_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title before year\n",
    "df.loc[12, \"Reference\"] = \"(2002). Director's forum. Laboratory Equipment, 38(12), 8. Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=6395811&site=ehost-live\"\n",
    "\n",
    "# 2.0 cuts title short\n",
    "df.loc[30, \"Reference\"] = 'Mohamed, A. (2007). Switch to web 2-0 boosts business agility for internet services firm. Computer Weekly, , 12-12. Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=25040565&site=ehost-live'\n",
    "\n",
    "# title before year\n",
    "df.loc[32, \"Reference\"] = '(2007). Translucent green: Environmentally-friendly manufacturing processes are key concern of retailers and brands. Textile World, 157(6), 49-49. Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=27662701&site=ehost-live'\n",
    "\n",
    "# title before year\n",
    "df.loc[38, \"Reference\"] = '(2008). Spiegel expands use of yunique software. Textile World, 158(4), 56-56. Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=33767368&site=ehost-live'\n",
    "\n",
    "# title before year\n",
    "df.loc[47, \"Reference\"] = '(2009). Service experience and service design: Concepts and application in tourism SMEs. Managing Service Quality, 19(3), 332-349. doi:10.1108/09604520910955339 Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=39983391&site=ehost-live'\n",
    "\n",
    "# no period to finish title\n",
    "df.loc[124, \"Reference\"] = 'Comerio, M., Batini, C., Castelli, M., Grega, S., Rossetti, M., & Viscusi, G. (2015). Service portfolio management: A repository-based framework. doi:10.1016/j.jss.2015.01.055'\n",
    "\n",
    "# title before year\n",
    "df.loc[148, \"Reference\"] = \"(2016). How to create a 'lights out' customer experience. Ivey Business Journal, , 5-7. Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=113229191&site=ehost-live\"\n",
    "\n",
    "# no period to finish title\n",
    "df.loc[155, \"Reference\"] = 'Peng, K., & Lin, P. M. C. (2016). Social entrepreneurs: Innovating rural tourism through the activism of service science. doi:10.1108/IJCHM-12-2014-0611'\n",
    "\n",
    "# no period to finish title\n",
    "df.loc[205, \"Reference\"] = 'Woo, J. (2017). How Chinese commercial banks innovate: process and practice. Journal of Innovation Management, 5(2), 81-110.'\n",
    "\n",
    "# title before year\n",
    "df.loc[211, \"Reference\"] = '(2018). Achieving competitive advantage. Strategic Direction, 34(10), 25-27. doi:10.1108/SD-06-2018-0145 Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=132294917&site=ehost-live'\n",
    "\n",
    "# 4.0 cuts title short\n",
    "df.loc[228, \"Reference\"] = 'MOHELSKA, H., & SOKOLOVA, M. (2018). Management approaches for industry 4-0 - the organizational culture perspective. Technological & Economic Development of Economy, 24(6), 2225-2240. doi:10.3846/tede.2018.6397 Retrieved from http://ezproxy.insead.edu:80/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=133233122&site=ehost-live'\n",
    "\n",
    "# df.to_csv(\"./data/text_allyears.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, PorterStemmer\n",
    "\n",
    "abbreviations = set([\"pss\", \"iot\", \"abs\", \"business\", \"exs\", \"ict\", \"npd\", \"bmi\", \"iot\", \"cem\", \"sst\", \"ic\", \"qos\", \"oi\", \"om\", \"psf\", \"ai\", \"bm\", \"bo\", \"mc\", \"mosp\", \"msd\", \"pssldm\", \"fcbpss\", \"ffe\", \"fmea\", \"fo\", \"iis\", \"sc\", \"sdl\", \"si\", \"sp\", \"vsm\", \"xe\", \"cad\", \"cdf\", \"clscs\", \"cmm\", \"cx\", \"ks\", \"odf\", \"sspss\", \"bma\", \"bpm\", \"bsc\", \"exs\", \"fof\", \"kibs\", \"lbd\", \"lo\", \"moss\", \"plm\", \"pnss\", \"prs\", \"qfd\", \"sem\", \"som\", \"sp\", \"acm\", \"adkar\", \"catwoe\", \"cc\", \"ces\", \"cis\", \"cit\", \"clv\", \"cxm\", \"dfsi\", \"dsic\", \"fepss\", \"fsqca\", \"ilp\", \"moa\", \"mosc\", \"ri\", \"rpn\", \"rrs\", \"rsp\", \"scm\", \"slr\", \"sna\", \"spesa\", \"spss\", \"ssm\", \"sta\", \"tr\", \"vo\", \"wips\"])\n",
    "def lemmatize(s):\n",
    "    return \" \".join([en.lemma(w) if w not in abbreviations else w for w in s.split()])\n",
    "\n",
    "cp1252_pattern = re.compile(u\"“|”|’|‘|—|–|–|\\?\")\n",
    "def strip_cp1252_punctuation(s):\n",
    "    return re.sub(cp1252_pattern, \" \", s)\n",
    "\n",
    "first_exclusion_common_terms = [\"service\", \"innovation\", \"design\", \"customer\", \"services\", \"research\", \"study\", \"paper\"]\n",
    "second_exclusion_common_terms = [\"service\", \"services\", \"research\", \"study\", \"paper\", \"result\", \"based\", \"literature\", \"article\", \"focus\"]\n",
    "def remove_common_terms(s, exclusion_terms):\n",
    "    return \" \".join([w for w in s.split() if w not in exclusion_terms])\n",
    "\n",
    "synonyms = {\"servitization\": \"servitisation\", \"consumer\": \"customer\"}\n",
    "def standardize_synonyms(s):\n",
    "    return \" \".join([synonyms.get(w, w) for w in s.split()])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def tokenizer(text):\n",
    "    return [stemmer.stem(token) if token not in abbreviations else token for token in word_tokenize(text)]\n",
    "\n",
    "def build_stem_to_token(iterator):\n",
    "    frequency_map = {}\n",
    "    \n",
    "    def do_stem_to_token(agg):\n",
    "        try:\n",
    "            _, text = next(iterator)\n",
    "            \n",
    "            for token in word_tokenize(text):\n",
    "                frequency_map[token] = frequency_map.get(token, 0) + 1\n",
    "                \n",
    "                if token not in abbreviations:\n",
    "                    stem = stemmer.stem(token)\n",
    "                    \n",
    "                    # only add token to aggregator if (i) not present or (ii) token is more popular than current one\n",
    "                    if stem not in agg.keys() or frequency_map[token] > frequency_map[agg[stem]]:\n",
    "                        agg[stem] = token\n",
    "\n",
    "            return do_stem_to_token(agg)\n",
    "        except StopIteration:\n",
    "            return agg\n",
    "        \n",
    "    result = {}\n",
    "    return do_stem_to_token(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_preprocessing(df, dfname=\"Abstract\", include_title=False, exclusion_terms=second_exclusion_common_terms):\n",
    "    if include_title:\n",
    "        raw_data = reference_preprocessing(df) + \" \" + df[\"Abstract\"]\n",
    "    else:\n",
    "        raw_data = df[\"Abstract\"]\n",
    "    \n",
    "    return raw_data.apply(str).apply(preprocess_string, filters=[\n",
    "        lambda x: x.lower(),\n",
    "        strip_tags,\n",
    "        strip_cp1252_punctuation,\n",
    "        strip_punctuation, \n",
    "        strip_multiple_whitespaces, \n",
    "        strip_numeric, \n",
    "        remove_stopwords, \n",
    "        strip_short,\n",
    "        lemmatize,\n",
    "        lambda x: remove_common_terms(x, exclusion_terms),\n",
    "        standardize_synonyms\n",
    "    ]).reset_index(drop=True).rename(dfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_abstracts = abstract_preprocessing(df, include_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import scipy.cluster.hierarchy as shc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative_cluster(X, n_clusters, with_model=False):\n",
    "    labels = shc.fcluster(shc.linkage(X, method='ward'), n_clusters, criterion='maxclust') - 1\n",
    "    \n",
    "    # for consistency between clusters\n",
    "    if with_model:\n",
    "        return labels, None\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def k_means_cluster(X, n_clusters, random_state=42, with_model=False, **kwargs):\n",
    "    km_model = KMeans(n_clusters=n_clusters, random_state=random_state, n_jobs=-1, n_init=50, **kwargs)\n",
    "    km_model.fit(X)\n",
    "    \n",
    "    if with_model:\n",
    "        return km_model.labels_, km_model\n",
    "\n",
    "    return km_model.labels_\n",
    "\n",
    "def nmf_cluster(X, n_clusters, frobenius=True, random_state=42, with_model=False, **kwargs):\n",
    "    if frobenius:\n",
    "        nmf = NMF(n_components=n_clusters, random_state=random_state, shuffle=True, alpha=.1, **kwargs)\n",
    "    else:\n",
    "        nmf = NMF(n_components=n_clusters, random_state=random_state, shuffle=True, beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1, **kwargs)\n",
    "\n",
    "    H = nmf.fit_transform(X)\n",
    "    W = nmf.components_\n",
    "    \n",
    "    cluster_labels = H.argmax(axis=1)\n",
    "    \n",
    "    if with_model:\n",
    "        return cluster_labels, nmf\n",
    "    \n",
    "    return cluster_labels\n",
    "    \n",
    "\n",
    "cluster_name_map = {\n",
    "    agglomerative_cluster: \"agglomerative\",\n",
    "    k_means_cluster: \"k_means\",\n",
    "    nmf_cluster: \"nmf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf Transformer Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_tfidf_scores(dct, corpus, n=None):\n",
    "    total_score = {}\n",
    "    \n",
    "    for document in corpus:\n",
    "        sorted_doc = sorted(document, key=(lambda x: (x[1], x[0])), reverse=True)\n",
    "        for kwd_id, tfidf_score in sorted_doc[:n]:\n",
    "            kwd = dct[kwd_id]\n",
    "            \n",
    "            if kwd not in total_score:\n",
    "                total_score[kwd] = 0\n",
    "                \n",
    "            total_score[kwd] += tfidf_score\n",
    "            \n",
    "    return sorted(total_score.items(), key=(lambda x: (x[1], x[0])), reverse=True)\n",
    "\n",
    "def tfidf_transformer_keyword_scores(clusters, word_count=6, debug=False, exclude_words=[], abstracts=preprocessed_abstracts, **kwds):\n",
    "    dct = corpora.Dictionary(abstracts)\n",
    "    model = TfIdfTransformer(dictionary=dct)\n",
    "\n",
    "    # train model on all documents\n",
    "    all_docs_corpus = abstracts.apply(dct.doc2bow).tolist()\n",
    "    model.fit(all_docs_corpus)\n",
    "\n",
    "    # create corpus per cluster\n",
    "    cluster_corpus = abstracts.groupby(clusters).apply(lambda x: [dct.doc2bow(abstract) for abstract in x])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for cluster_id, corpus in cluster_corpus.items():\n",
    "        tfidf_corpus = model.transform(corpus)\n",
    "\n",
    "        words_in_cluster = 0\n",
    "        for keyword, score in sum_tfidf_scores(dct, tfidf_corpus):\n",
    "            if keyword in exclude_words: continue\n",
    "            result.append((cluster_id, keyword, score))\n",
    "            words_in_cluster += 1\n",
    "            \n",
    "            if words_in_cluster == word_count:\n",
    "                break\n",
    "\n",
    "    return pd.DataFrame(result, columns=[\"cluster\", \"keyword\", \"score\"])\n",
    "\n",
    "def plot_keyword_scores(X_scores, n_clusters, name, keyword_algo=tfidf_transformer_keyword_scores, config_name=\"default\", keyword_algo_name=None, savefig=True):\n",
    "    fig, axes = plt.subplots(nrows=n_clusters, sharey=True)\n",
    "    \n",
    "    if keyword_algo_name is None:\n",
    "        keyword_algo_name = keyword_name_map[keyword_algo]\n",
    "        \n",
    "    fig.suptitle(f\"Cluster Themes (k={n_clusters}) - {name} - {keyword_algo_name} - {config_name}\", fontsize=35)\n",
    "    fig.set_figheight(n_clusters * 5)\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        cluster_num = i\n",
    "        \n",
    "        sns.barplot(\n",
    "            x='keyword',  \n",
    "            y='score',  \n",
    "            data=X_scores[X_scores['cluster'] == cluster_num],\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"cluster={cluster_num}\")\n",
    "        ax.set_xlabel(None)\n",
    "        ax.tick_params(axis='x', labelsize=40)\n",
    "    \n",
    "    if savefig:\n",
    "        fig.savefig(f'plots/{name}/{config_name}/{n_clusters}/keywords_{keyword_algo_name}.pdf', format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_name_map = {\n",
    "    tfidf_transformer_keyword_scores: \"tfidf_transformer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Evaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, calinski_harabasz_score, davies_bouldin_score, pairwise_distances_argmin_min\n",
    "from gensim import corpora\n",
    "from gensim.sklearn_api import TfIdfTransformer\n",
    "from gensim.summarization import keywords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from PyPDF2 import PdfFileMerger\n",
    "\n",
    "class ClusterEvaluator:\n",
    "    def __init__(self, X, name, model=None, cluster_algo=k_means_cluster, config_name=\"default\", abstracts=preprocessed_abstracts):\n",
    "        self.X = X\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.config_name = config_name\n",
    "        \n",
    "        self.cluster_labels = {}\n",
    "        self.cluster_models = {}\n",
    "        \n",
    "        self.cluster_algo = cluster_algo\n",
    "        self.abstracts = abstracts\n",
    "        \n",
    "        self.stem_to_token = build_stem_to_token(abstracts.apply(\" \".join).iteritems())\n",
    "        \n",
    "    def get_cluster_labels(self, k):\n",
    "        if k not in self.cluster_labels.keys():\n",
    "            self.cluster_labels[k], self.cluster_models[k] = self.cluster_algo(self.X, k, with_model=True)\n",
    "        \n",
    "        return self.cluster_labels[k]\n",
    "    \n",
    "    def calinski_harabasz_evaluation(self, n_clusters_limit, **kwargs):\n",
    "        self.univariate_method_evaluation(n_clusters_limit, calinski_harabasz_score, \"calinski_harabasz\", **kwargs)\n",
    "\n",
    "    def davies_bouldin_evaluation(self, n_clusters_limit, **kwargs):\n",
    "        self.univariate_method_evaluation(n_clusters_limit, davies_bouldin_score, \"davies_bouldin\", **kwargs)\n",
    "\n",
    "    def average_silhouette_evaluation(self, n_clusters_limit, **kwargs):\n",
    "        self.univariate_method_evaluation(n_clusters_limit, silhouette_score, \"silhouette\", **kwargs)\n",
    "        \n",
    "    def univariate_method_evaluation(self, n_clusters_limit, score_metric, score_metric_name, savefig=True, **kwargs):\n",
    "        assert n_clusters_limit >= 2\n",
    "\n",
    "        k_range = range(2, n_clusters_limit)\n",
    "\n",
    "        plt.title(f'{score_metric_name} Scores (max_k={n_clusters_limit})')\n",
    "\n",
    "        if self.cluster_algo == agglomerative_cluster:\n",
    "            X_n = spatial.distance.squareform(self.X)\n",
    "        else:\n",
    "            X_n = self.X.toarray()\n",
    "\n",
    "        scores = []\n",
    "        for k in k_range:\n",
    "            cluster_labels = self.get_cluster_labels(k)\n",
    "\n",
    "            scores.append(score_metric(X_n, cluster_labels))\n",
    "\n",
    "        plt.plot(k_range, scores, label=self.config_name, **kwargs)\n",
    "\n",
    "        plt.legend()\n",
    "        \n",
    "        if savefig:\n",
    "            plt.savefig(f'plots/{self.name}/{self.config_name}/{score_metric_name}_scores.pdf')\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "    def silhouette(self, k):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        if self.cluster_algo == agglomerative_cluster:\n",
    "            X = spatial.distance.squareform(self.X)\n",
    "        else:\n",
    "            X = self.X\n",
    "            \n",
    "        cluster_labels = self.get_cluster_labels(k)\n",
    "    \n",
    "        silhouette_avg = silhouette_score(X, cluster_labels, sample_size=None)\n",
    "        samples = silhouette_samples(X, cluster_labels)\n",
    "    \n",
    "        max_silhouette_score = np.max(samples)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(0, k):\n",
    "            cluster_silhouette_scores = samples[cluster_labels == i]\n",
    "            cluster_silhouette_scores.sort()\n",
    "            cluster_size = cluster_silhouette_scores.shape[0]\n",
    "            \n",
    "            y_upper = y_lower + cluster_size\n",
    "\n",
    "            ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_scores)\n",
    "            ax.text(-0.1 * max_silhouette_score, y_lower + 0.5 * cluster_size, str(i))\n",
    "\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        plt.title(f'Silhouette Graph (k={k}) - {self.name} - {self.config_name}')\n",
    "\n",
    "        ax.set_yticks([])\n",
    "        ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "        plt.text(silhouette_avg + 0.01,20,f'silhouette_avg={np.round(silhouette_avg, 4)}')\n",
    "        plt.savefig(f'plots/{self.name}/{self.config_name}/{k}/silhouette.pdf')\n",
    "        plt.show()\n",
    "        \n",
    "    def tsne(self, k, random_state=0, **kwargs):\n",
    "        X = self.X\n",
    "        cluster_labels = self.get_cluster_labels(k)\n",
    "        \n",
    "        X_truncated = TruncatedSVD(n_components=k, random_state=random_state).fit_transform(X)\n",
    "        X_repr = TSNE(n_components=2, random_state=random_state, **kwargs).fit_transform(X_truncated)\n",
    "\n",
    "        fig = plt.subplot()\n",
    "        sns.scatterplot(X_repr[:, 0], X_repr[:, 1], s=1000, hue=cluster_labels, palette=\"Set3\", legend=\"full\")\n",
    "        plt.title(f'TSNE 2-d Representation (k={k}) - {self.name} - {self.config_name}')\n",
    "        plt.savefig(f'plots/{self.name}/{self.config_name}/{k}/tsne.pdf')\n",
    "        plt.show()\n",
    "        \n",
    "    def format_keyword(self, keyword):\n",
    "        return \" \".join([self.stem_to_token.get(w, w) for w in keyword.split()])\n",
    "        \n",
    "    def k_means_centers_nearest_papers(self, k, df):\n",
    "        assert self.cluster_algo == k_means_cluster\n",
    "\n",
    "        cluster_labels = self.get_cluster_labels(k)\n",
    "        kmeans = self.cluster_models[k]\n",
    "        \n",
    "        if kmeans is None:\n",
    "            raise Exception(f\"Cluster model for {k} does not exist.\")\n",
    "            \n",
    "        nearest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, self.X)\n",
    "        \n",
    "        nearest_papers_df = df.iloc[nearest].reset_index(drop=True)\n",
    "        nearest_papers_df.to_csv(f\"./plots/{self.name}/{self.config_name}/{k}/most_representative_papers.csv\")\n",
    "        \n",
    "    def k_means_centers_keywords_scores(self, k, word_count=6):\n",
    "        assert self.cluster_algo == k_means_cluster\n",
    "\n",
    "        cluster_labels = self.get_cluster_labels(k)\n",
    "        kmeans = self.cluster_models[k]\n",
    "\n",
    "        if kmeans is None:\n",
    "            raise Exception(f\"Cluster model for {k} does not exist.\")\n",
    "\n",
    "        cluster_center_feature_names_df = pd.DataFrame(kmeans.cluster_centers_.transpose(), index=self.model.get_feature_names())\n",
    "        non_zero_mask = ~cluster_center_feature_names_df.eq(0)\n",
    "\n",
    "        result = [] \n",
    "\n",
    "        for label in cluster_labels:\n",
    "            cluster_df = cluster_center_feature_names_df[non_zero_mask][label].dropna()\n",
    "\n",
    "            for keyword, scores in cluster_df.sort_values(ascending=False).iloc[:word_count].iteritems():\n",
    "                result.append((label, self.format_keyword(keyword), scores))\n",
    "\n",
    "        X_scores = pd.DataFrame(result, columns=[\"cluster\", \"keyword\", \"score\"])\n",
    "        \n",
    "        plot_keyword_scores(X_scores, k, self.name, config_name=self.config_name, keyword_algo_name=\"k_means_centers\")\n",
    "            \n",
    "    def keywords(self, k, keyword_algo=tfidf_transformer_keyword_scores, savefig=True, **kwds):\n",
    "        cluster_labels = self.get_cluster_labels(k)\n",
    "        \n",
    "        X_scores = keyword_algo(cluster_labels, abstracts=self.abstracts, stem_to_token=self.stem_to_token, **kwds)\n",
    "        plot_keyword_scores(X_scores, k, self.name, keyword_algo, self.config_name, savefig=savefig)\n",
    "        \n",
    "    def nmf_decomp(self, frobenius=True, n_topics=10, word_count=10, random_state=42, **kwargs):\n",
    "        if frobenius:\n",
    "            # NMF - Frobenius\n",
    "            nmf = NMF(n_components=n_topics, random_state=random_state, shuffle=True, alpha=.1)\n",
    "        else:\n",
    "            # NMF - Kullback-leiber\n",
    "            nmf = NMF(n_components=n_topics, random_state=random_state, shuffle=True, beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1, l1_ratio=.5)\n",
    "            \n",
    "        H = nmf.fit_transform(self.X)\n",
    "        W = nmf.components_\n",
    "        \n",
    "        return W, H\n",
    "        \n",
    "        feature_names = self.model.get_feature_names()\n",
    "\n",
    "        result = []\n",
    "        \n",
    "        for topic_id, topic in enumerate(H):\n",
    "            topic_top_words = topic.argsort()[::-1][:word_count]\n",
    "            \n",
    "            result.append(', '.join([self.format_keyword(feature_names[i]) for i in topic_top_words]))\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def merge(self, pdfnames):\n",
    "        for pdfname in pdfnames:\n",
    "            merger = PdfFileMerger()\n",
    "            \n",
    "            for k in sorted(self.cluster_labels.keys()):\n",
    "                try:\n",
    "                    pdf_path = f\"./plots/{self.name}/{self.config_name}/{k}/{pdfname}.pdf\"\n",
    "                    merger.append(pdf_path)\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                \n",
    "\n",
    "            merger.write(f\"./plots/{self.name}/{self.config_name}/all_{pdfname}.pdf\")\n",
    "            merger.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "if \"tfidf\" not in os.listdir(\"./plots\"):\n",
    "    os.mkdir(\"./plots/tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_model = TfidfVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    tokenizer=tokenizer, \n",
    "    min_df=2, # must appear in more than one document\n",
    "    max_df=0.99 # must appear in fewer than 99% of documents \n",
    ")\n",
    "\n",
    "config_name = \"unigram\"\n",
    "\n",
    "unigram_scores = unigram_model.fit_transform(preprocessed_abstracts.apply(\" \".join).values)\n",
    "unigram_evaluator = ClusterEvaluator(unigram_scores, \"tfidf\", model=unigram_model, config_name=config_name)\n",
    "\n",
    "if config_name not in os.listdir(\"./plots/tfidf\"):\n",
    "    os.mkdir(f\"./plots/tfidf/{config_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uW, uH = unigram_evaluator.nmf_decomp(n_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_cluster_labels = uH.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_preprocessing(df[nmf_cluster_labels == 10]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "unigram_evaluator.average_silhouette_evaluation(30)\n",
    "unigram_evaluator.calinski_harabasz_evaluation(30)\n",
    "unigram_evaluator.davies_bouldin_evaluation(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for k in [3, 6, 9, 12, 18]:\n",
    "    if str(k) not in os.listdir(\"./plots/tfidf/\" + \"unigram\"):\n",
    "        os.mkdir(f\"./plots/tfidf/unigram/{k}\")\n",
    "        \n",
    "    unigram_evaluator.silhouette(k)\n",
    "    unigram_evaluator.tsne(k)\n",
    "    unigram_evaluator.keywords(k, keyword_algo=tfidf_vectorizer_keyword_scores)\n",
    "    unigram_evaluator.keywords(k, keyword_algo=tfidf_transformer_keyword_scores)\n",
    "    unigram_evaluator.k_means_centers_keywords_scores(k)\n",
    "    unigram_evaluator.k_means_centers_nearest_papers(k, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_evaluator.merge([\"silhouette\", \"tsne\", \"keywords_tfidf_transformer\", \"keywords_k_means_centers\", \"keywords_tfidf_vectorizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), # search for unigrams and bigrams\n",
    "    tokenizer=tokenizer,\n",
    "    min_df=3,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "config_name = \"bigram\"\n",
    "\n",
    "bigram_scores = bigram_model.fit_transform(preprocessed_abstracts.apply(\" \".join).values)\n",
    "bigram_evaluator = ClusterEvaluator(bigram_scores, \"tfidf\", model=bigram_model, config_name=config_name)\n",
    "\n",
    "if config_name not in os.listdir(\"./plots/tfidf\"):\n",
    "    os.mkdir(\"./plots/tfidf/\" + config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigram_evaluator.average_silhouette_evaluation(30)\n",
    "bigram_evaluator.calinski_harabasz_evaluation(30)\n",
    "bigram_evaluator.davies_bouldin_evaluation(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [6, 8, 9, 12, 15, 19]:\n",
    "    if str(k) not in os.listdir(f\"./plots/tfidf/{bigram_evaluator.config_name}\"):\n",
    "        os.mkdir(f\"./plots/tfidf/{bigram_evaluator.config_name}/{k}\")\n",
    "        \n",
    "    bigram_evaluator.silhouette(k)\n",
    "    bigram_evaluator.tsne(k)\n",
    "    bigram_evaluator.keywords(k, keyword_algo=tfidf_transformer_keyword_scores)\n",
    "    bigram_evaluator.keywords(k, keyword_algo=tfidf_vectorizer_keyword_scores)\n",
    "    bigram_evaluator.k_means_centers_keywords_scores(k)\n",
    "    bigram_evaluator.k_means_centers_nearest_papers(k, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigram_evaluator.print_nmf_topics(n_topics=20, word_count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_evaluator.merge([\"silhouette\", \"tsne\", \"keywords_tfidf_transformer\", \"keywords_k_means_centers\", \"keywords_tfidf_vectorizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multigram_model = TfidfVectorizer(\n",
    "    ngram_range=(1, 5),\n",
    "    tokenizer=tokenizer,\n",
    "    min_df=3,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "multigram_scores = multigram_model.fit_transform(preprocessed_abstracts.apply(\" \".join).values)\n",
    "multigram_evaluator = ClusterEvaluator(multigram_scores, \"tfidf\", model=multigram_model, config_name=f\"multigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multigram_evaluator.average_silhouette_evaluation(30)\n",
    "multigram_evaluator.calinski_harabasz_evaluation(30)\n",
    "multigram_evaluator.davies_bouldin_evaluation(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"multigram\" not in os.listdir(\"./plots/tfidf\"):\n",
    "    os.mkdir(\"./plots/tfidf/multigram\")\n",
    "for k in [8, 11, 12, 15]:\n",
    "    if str(k) not in os.listdir(\"./plots/tfidf/multigram\"):\n",
    "        os.mkdir(f\"./plots/tfidf/multigram/{k}\")\n",
    "        \n",
    "#     multigram_evaluator.silhouette(k)\n",
    "#     multigram_evaluator.tsne(k)\n",
    "#     multigram_evaluator.keywords(k, keyword_algo=tfidf_transformer_keyword_scores)\n",
    "#     multigram_evaluator.keywords(k, keyword_algo=tfidf_vectorizer_keyword_scores)\n",
    "#     multigram_evaluator.k_means_centers_keywords_scores(k)\n",
    "    multigram_evaluator.k_means_centers_nearest_papers(k, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multigram_evaluator.print_nmf_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multigram_evaluator.merge([\"silhouette\", \"tsne\", \"keywords_tfidf_transformer\", \"keywords_k_means_centers\", \"keywords_tfidf_vectorizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 20\n",
    "nmf_df = pd.DataFrame(index=range(n_topics))\n",
    "nmf_df[\"unigram\"] = unigram_evaluator.nmf_topics(n_topics=n_topics, word_count=6)\n",
    "nmf_df[\"bigram\"] = bigram_evaluator.nmf_topics(n_topics=n_topics, word_count=6)\n",
    "nmf_df[\"multigram\"] = multigram_evaluator.nmf_topics(n_topics=n_topics, word_count=6)\n",
    "\n",
    "nmf_df.to_csv(f\"results/nmf_topics_{n_topics}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = df.copy()\n",
    "\n",
    "tfidf_df[f\"unigram_6\"] = unigram_evaluator.get_cluster_labels(6)\n",
    "tfidf_df[f\"unigram_9\"] = unigram_evaluator.get_cluster_labels(9)\n",
    "tfidf_df[f\"unigram_12\"] = unigram_evaluator.get_cluster_labels(12)\n",
    "\n",
    "tfidf_df[f\"bigram_8\"] = bigram_evaluator.get_cluster_labels(8)\n",
    "tfidf_df[f\"bigram_9\"] = bigram_evaluator.get_cluster_labels(9)\n",
    "tfidf_df[f\"bigram_12\"] = bigram_evaluator.get_cluster_labels(12)\n",
    "tfidf_df[f\"bigram_15\"] = bigram_evaluator.get_cluster_labels(15)\n",
    "tfidf_df[f\"bigram_19\"] = bigram_evaluator.get_cluster_labels(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.to_csv('results/tfidf_clusters_ngrams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Mover's Distance on GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def convert_glove_2_w2v():\n",
    "    tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "\n",
    "    glove2word2vec(\"./data/glove.6B/glove.6B.50d.txt\", tmp_file)\n",
    "\n",
    "    return KeyedVectors.load_word2vec_format(tmp_file)\n",
    "    \n",
    "# model = convert_glove_2_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix():\n",
    "    s = preprocessed_abstracts.size\n",
    "    result = np.ndarray((s,s))\n",
    "    \n",
    "    for i, a1 in enumerate(preprocessed_abstracts):\n",
    "        print(f\"({i}/{s}) Calculating distance for abstract...\")\n",
    "        for j, a2 in enumerate(preprocessed_abstracts.iloc[i:]):\n",
    "            distance = model.wmdistance(a1, a2)\n",
    "            result[i][i + j] = distance\n",
    "            result[i + j][i] = distance\n",
    "            print(f\"D_({i}, {i + j})={distance}\")\n",
    "            \n",
    "    return result\n",
    "\n",
    "# abstract_distance_matrix = calculate_distance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store distance matrix\n",
    "# pd.DataFrame(abstract_distance_matrix).to_csv('data/last_distance_matrix.csv')\n",
    "# load distance matrix from memory\n",
    "abstract_distance_matrix = pd.read_csv('data/last_distance_matrix.csv', index_col=0).values\n",
    "# create the squareform\n",
    "abstract_df = spatial.distance.squareform(abstract_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_evaluator = ClusterEvaluator(abstract_df, \"wmd_glove\", config_name=f\"last\", cluster_algo=agglomerative_cluster)\n",
    "\n",
    "if \"last\" not in os.listdir(\"./plots/wmd_glove\"):\n",
    "    os.mkdir(f\"./plots/wmd_glove/last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"All Years - Second Exlusion - Dendrogram\")\n",
    "dend = shc.dendrogram(shc.linkage(abstract_df, method='ward'))\n",
    "plt.savefig('plots/wmd_glove/dendrogram.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2, 12):\n",
    "    if str(i) not in os.listdir(\"./plots/wmd_glove/last\"):\n",
    "        os.mkdir(f\"./plots/wmd_glove/last/{i}\")\n",
    "        \n",
    "    wmd_evaluator.silhouette(i)\n",
    "    wmd_evaluator.keywords(i, keyword_algo=tfidf_transformer_keyword_scores)\n",
    "    wmd_evaluator.keywords(i, keyword_algo=tfidf_vectorizer_keyword_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_evaluator.average_silhouette_evaluation(20)\n",
    "wmd_evaluator.calinski_harabasz_evaluation(20)\n",
    "wmd_evaluator.davies_bouldin_evaluation(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_evaluator.merge([\"silhouette\", \"keywords_tfidf_transformer\", \"keywords_tfidf_vectorizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_df = df.copy()\n",
    "\n",
    "for k in range(2, 6):\n",
    "    wmd_df[f\"cluster_{k}\"] = wmd_evaluator.get_cluster_labels(k)\n",
    "    \n",
    "wmd_df.to_csv(\"results/wmd_glove_clusters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives\n",
    "\n",
    "### Topic Modeling\n",
    "\n",
    "It seems that there is not enough data available in our dataset (only ~300 paragraphs) to provide interesting results for topic modeling algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People-Centric - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_df = pd.read_csv(\"./archive/people_centric/data/abstracts.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_abstracts = abstract_preprocessing(people_centric_df, dfname=\"people_centric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_model = TfidfVectorizer(\n",
    "    ngram_range=(1, 1),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "people_centric_scores = people_centric_model.fit_transform(people_centric_abstracts.apply(\" \".join).values)\n",
    "people_centric_evaluator = ClusterEvaluator(people_centric_scores, \"people_centric\", config_name=f\"unigram\", abstracts=people_centric_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 12):\n",
    "    if str(i) not in os.listdir(\"./plots/people_centric/unigram\"):\n",
    "        os.mkdir(f\"./plots/people_centric/unigram/{i}\")\n",
    "    \n",
    "    people_centric_evaluator.silhouette(i)\n",
    "    people_centric_evaluator.tsne(i)\n",
    "    people_centric_evaluator.keywords(i, keyword_algo=tfidf_transformer_keyword_scores)\n",
    "    people_centric_evaluator.keywords(i, keyword_algo=tfidf_vectorizer_keyword_scores)\n",
    "    people_centric_evaluator.k_means_centers_keywords_scores(people_centric_model, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_evaluator.average_silhouette_evaluation(20)\n",
    "people_centric_evaluator.calinski_harabasz_evaluation(20)\n",
    "people_centric_evaluator.davies_bouldin_evaluation(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_evaluator.merge([\"silhouette\", \"tsne\", \"keywords_tfidf_transformer\", \"keywords_tfidf_vectorizer\", \"keywords_k_means_centers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_tfidf_df = people_centric_df.copy()\n",
    "\n",
    "for k in range(5, 9):\n",
    "    people_centric_tfidf_df[f\"cluster_{k}\"] = people_centric_evaluator.get_cluster_labels(k)\n",
    "    \n",
    "people_centric_tfidf_df.to_csv(\"./results/people_centric_tfidf_clusters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People-Centric - WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_abstract_df = pd.read_csv(\"./archive/people_centric/data/whole_abstract_distance_matrix.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_wmd_evaluator = ClusterEvaluator(people_centric_abstract_df, \"people_centric\", config_name=f\"wmd_glove\", cluster_algo=agglomerative_cluster)\n",
    "\n",
    "if \"wmd_glove\" not in os.listdir(\"./plots/people_centric\"):\n",
    "    os.mkdir(f\"./plots/people_centric/wmd_glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_centric_wmd_df = people_centric_df.copy()\n",
    "\n",
    "for k in range(5, 9):\n",
    "    people_centric_wmd_df[f\"cluster_{k}\"] = people_centric_wmd_evaluator.get_cluster_labels(k) \n",
    "    \n",
    "\n",
    "people_centric_wmd_df.to_csv(\"./results/people_centric_wmd_clusters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below has been moved into the Evaluator class or has now become obselete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_evaluation(X, n_clusters, name, cluster_algo=k_means_cluster, config_name=\"default\", squareform=False):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    cluster_labels = cluster_algo(X, n_clusters)\n",
    "    \n",
    "    if squareform:\n",
    "        X = spatial.distance.squareform(X)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X, cluster_labels, sample_size=None)\n",
    "    samples = silhouette_samples(X, cluster_labels)\n",
    "    \n",
    "    max_silhouette_score = np.max(samples)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(0, n_clusters):\n",
    "        cluster_silhouette_scores = samples[cluster_labels == i]\n",
    "        cluster_silhouette_scores.sort()\n",
    "\n",
    "        cluster_size = cluster_silhouette_scores.shape[0]\n",
    "        y_upper = y_lower + cluster_size\n",
    "\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_scores)\n",
    "\n",
    "        ax.text(-0.1 * max_silhouette_score, y_lower + 0.5 * cluster_size, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    plt.title(f'Silhouette Graph (k={n_clusters}) - {name} - {config_name}')\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    plt.text(silhouette_avg + 0.01,20,f'silhouette_avg={np.round(silhouette_avg, 4)}')\n",
    "    plt.savefig(f'plots/{name}/{n_clusters}/silhouette_{config_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_evaluation(X, n_clusters, name, random_state=0, config_name=\"default\", **kwargs):\n",
    "    labels = k_means_cluster(X, n_clusters)\n",
    "    X_truncated = TruncatedSVD(n_components=n_clusters, random_state=random_state).fit_transform(X)\n",
    "    X_repr = TSNE(n_components=2, random_state=random_state, **kwargs).fit_transform(X_truncated)\n",
    "\n",
    "    fig = plt.subplot()\n",
    "    sns.scatterplot(X_repr[:, 0], X_repr[:, 1], s=1000, hue=labels, palette=\"Set3\", legend=\"full\")\n",
    "    plt.title(f'TSNE 2-d Representation (k={n_clusters}) - {name} - {config_name}')\n",
    "\n",
    "    plt.savefig(f'plots/{name}/{n_clusters}/tsne_{config_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf Vectorizer Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_keyword_scores_cache = {}\n",
    "\n",
    "\n",
    "def tfidf_vectorizer_keyword_scores(clusters, word_count=6, abstracts=preprocessed_abstracts, stem_to_token=None, **kwargs):\n",
    "    result = []\n",
    "    \n",
    "    # join abstract strings \n",
    "    abstract_strings = abstracts.apply(\" \".join)\n",
    "    \n",
    "    # get or store vectorizer model in cache\n",
    "    if abstracts.name not in tfidf_vectorizer_keyword_scores_cache:\n",
    "        model = TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1, 2), max_features=5000, **kwargs)\n",
    "        model.fit(abstract_strings.values)\n",
    "        \n",
    "        tfidf_vectorizer_keyword_scores_cache[abstracts.name] = model\n",
    "    else:\n",
    "        model = tfidf_vectorizer_keyword_scores_cache[abstracts.name]\n",
    "        \n",
    "    general_idf_ = pd.Series(model.idf_, index=model.get_feature_names())\n",
    "        \n",
    "    # for each cluster\n",
    "    for cluster_id, cluster_idx in abstracts.groupby(clusters).groups.items():\n",
    "        # get the associated abstracts\n",
    "        abstracts = abstract_strings.loc[cluster_idx]\n",
    "        \n",
    "        abstracts_scores = model.transform(abstracts.values)\n",
    "        \n",
    "        # put them in a dataframe where each word vector is a row\n",
    "        abstracts_scores_df = pd.DataFrame.sparse.from_spmatrix(abstracts_scores.transpose(), index=model.get_feature_names())\n",
    "        \n",
    "        # remove all keywords that don't appear in the cluster for performance\n",
    "        keyword_in_cluster_mask = ~abstracts_scores_df.sum(1).eq(0)\n",
    "        abstracts_scores_df = abstracts_scores_df[keyword_in_cluster_mask]\n",
    "        \n",
    "        # accumulate scores based on the global idf\n",
    "        abstracts_scores_df = abstracts_scores_df.sum(1).mul(general_idf_[keyword_in_cluster_mask], axis=0).dropna()\n",
    "\n",
    "        # sort the dataframe by the cumulative idf scores\n",
    "        sorted_keyword_scores = abstracts_scores_df.sort_values(ascending=False)\n",
    "        \n",
    "        for keyword, score in sorted_keyword_scores.iloc[:word_count].iteritems():\n",
    "            if stem_to_token is not None:\n",
    "                keyword =  \" \".join([stem_to_token.get(w, w) for w in keyword.split()])\n",
    "            \n",
    "            result.append((cluster_id, keyword, score))\n",
    "        \n",
    "    return pd.DataFrame(result, columns=[\"cluster\", \"keyword\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmed_keyword_mean_score(keywords):\n",
    "    stemmed_scores = {}\n",
    "    stemmed2kwd = {}\n",
    "    \n",
    "    for kwd, score in keywords:\n",
    "        stemmed_kwd = stem_text(stem_text(kwd))\n",
    "        \n",
    "        if stemmed_kwd not in stemmed_scores:\n",
    "            stemmed2kwd[stemmed_kwd] = kwd\n",
    "            stemmed_scores[stemmed_kwd] = []\n",
    "\n",
    "        stemmed_scores[stemmed_kwd].append(score)\n",
    "        \n",
    "    stemmed_scores = {stemmed2kwd[k]: np.mean(v) for (k, v) in stemmed_scores.items()} \n",
    "            \n",
    "    return sorted(stemmed_scores.items(), key=(lambda x: (x[1], x[0])), reverse=True)\n",
    "\n",
    "def text_rank_keyword_scores(clusters, word_count=6, debug=False, abstracts=preprocessed_abstracts, **kwds):\n",
    "    result = []\n",
    "    \n",
    "    scored_keywords = abstracts.apply(\" \".join)\\\n",
    "                               .apply(lambda s: re.sub(u\"–\", \" \", s))\\\n",
    "                               .groupby(clusters)\\\n",
    "                               .apply(\". \".join)\\\n",
    "                               .apply(lambda x: keywords(x, scores=True, **kwds))\n",
    "    \n",
    "\n",
    "    for group, kw_list in scored_keywords.iteritems():\n",
    "        stemmed_keywords_seen = set([])\n",
    "        \n",
    "        for keyword, score in kw_list:\n",
    "            if len(stemmed_keywords_seen) == word_count:\n",
    "                break\n",
    "                \n",
    "            stemmed_keyword = stem_text(stem_text(keyword))\n",
    "            \n",
    "            if debug:\n",
    "                print(\", \".join([keyword, stemmed_keyword, str(score), str(stemmed_keywords_seen)]))\n",
    "            \n",
    "            if stemmed_keyword not in stemmed_keywords_seen:\n",
    "                stemmed_keywords_seen.add(stemmed_keyword)\n",
    "                result.append((group, keyword, score))\n",
    "            \n",
    "    return pd.DataFrame(result, columns=[\"cluster\", \"keyword\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_idf_scores = dict(filter(lambda x: len(x[0].split()) == 1, zip(bigram_model.get_feature_names(), bigram_model.idf_)))\n",
    "bigram_idf_scores = dict(filter(lambda x: len(x[0].split()) == 2, zip(bigram_model.get_feature_names(), bigram_model.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "pd.Series(unigram_idf_scores).plot.hist(bins=100, ax=ax)\n",
    "pd.Series(bigram_idf_scores).plot.hist(bins=100, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
